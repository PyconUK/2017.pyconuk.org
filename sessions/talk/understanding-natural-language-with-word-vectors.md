original_id: 54C7
title: "Understanding Natural Language with Word Vectors"
subtitle: ""
speaker: marco-bonzanini
track: pydata
video:
---
This talk is an introduction to word vectors, a.k.a. word embeddings, 
a family of Natural Language Processing (NLP) algorithms
where words are mapped to vectors.

An important property of these vector is
being able to capture semantic relationships,
for example:
UK - London + Paris = ???

These techniques have been driving important improvements in many NLP applications
over the past few years, so the interest around word embeddings is spreading.
In this talk, we'll discuss the basic linguistic intuitions behind word embeddings, 
we'll compare some of the most popular word embedding approaches, from word2vec
to fastText, and we'll showcase their use with Python libraries.

The aim of the talk is to be approachable for beginners,
so the theory is kept to a minimum.

By attending this talk, you'll be able to learn:
- the core features of word embeddings
- how to choose between different word embedding algorithms
- how to implement word embedding techniques in Python